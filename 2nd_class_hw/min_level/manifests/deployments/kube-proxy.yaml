apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-proxy
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:node-proxier
rules:
  - apiGroups: [""]
    resources: ["endpoints", "services", "pods", "nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "patch", "update"]
  - apiGroups: ["discovery.k8s.io"]
    resources: ["endpointslices"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
  - apiGroups: ["networking.k8s.io"]
    resources: ["networkpolicies"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system:node-proxier
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:node-proxier
subjects:
  - kind: ServiceAccount
    name: kube-proxy
    namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-proxy
  namespace: kube-system
data:
  config.conf: |
    apiVersion: kubeproxy.config.k8s.io/v1alpha1
    kind: KubeProxyConfiguration
    bindAddress: 0.0.0.0
    clientConnection:
      kubeconfig: /var/lib/kube-proxy/kubeconfig
    mode: "iptables"
    metricsBindAddress: "0.0.0.0:10249"
    # За потреби задай свій Pod CIDR (не обов'язково):
    # clusterCIDR: "10.22.0.0/16"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-proxy-kubeconfig
  namespace: kube-system
data:
  kubeconfig: |
    apiVersion: v1
    kind: Config
    clusters:
    - cluster:
        server: https://127.0.0.1:6443
        insecure-skip-tls-verify: true
      name: local
    contexts:
    - context:
        cluster: local
        user: sa
      name: local
    current-context: local
    users:
    - name: sa
      user:
        tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-proxy
  namespace: kube-system
  labels: { k8s-app: kube-proxy }
spec:
  selector:
    matchLabels: { k8s-app: kube-proxy }
  template:
    metadata:
      labels: { k8s-app: kube-proxy }
    spec:
      hostNetwork: true
      serviceAccountName: kube-proxy
      priorityClassName: system-node-critical
      tolerations:
        - operator: Exists
      containers:
        - name: kube-proxy
          image: registry.k8s.io/kube-proxy:v1.30.0
          command: ["/usr/local/bin/kube-proxy","--config=/var/lib/kube-proxy/config.conf","--v=2"]
          securityContext:
            privileged: true            # <-- головне
          env:
            - name: NODE_NAME
              valueFrom: { fieldRef: { fieldPath: spec.nodeName } }
          volumeMounts:
            - { name: config,          mountPath: /var/lib/kube-proxy }
            - { name: xtables-lock,    mountPath: /run/xtables.lock }
      volumes:
        - name: config
          projected:
            sources:
              - configMap:
                  name: kube-proxy
                  items: [{ key: config.conf, path: config.conf }]
              - configMap:
                  name: kube-proxy-kubeconfig
                  items: [{ key: kubeconfig, path: kubeconfig }]
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
